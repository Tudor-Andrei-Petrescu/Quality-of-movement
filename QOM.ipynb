{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "9aa9172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "7226a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the name of the subfolders containing the frames and the (x,y) coordinates \n",
    "subfolders = [ f.path for f in os.scandir('./jk_data_only_22') if f.is_dir() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "59507a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping class name to an integer\n",
    "class_labels = {}\n",
    "\n",
    "class_labels['correct'] = 0\n",
    "class_labels['incorrect_chin_tuck'] = 1\n",
    "class_labels['incorrect_lean_fwd'] = 2\n",
    "class_labels['incorrect_feet_close'] = 3\n",
    "class_labels['incorrect_not_low'] = 4\n",
    "class_labels['incorrect_out_knees'] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "5f179e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the name of the folder to the beginning of the filename(each folder has different file beginnings)\n",
    "folder_to_filename = {}\n",
    "\n",
    "\n",
    "folder_to_filename['a'] = 'DSC_0808_'\n",
    "folder_to_filename['ax'] = 'DSC_0801_'\n",
    "\n",
    "folder_to_filename['J_01'] = 'JVID2_'\n",
    "folder_to_filename['J_02'] = 'DSC_0704_'\n",
    "folder_to_filename['J_03'] = 'DSC_0703_'\n",
    "folder_to_filename['J_04'] = 'DSC_0702_'\n",
    "folder_to_filename['J_05'] = 'D4_'\n",
    "folder_to_filename['J_06'] = 'DSC_0707_'\n",
    "folder_to_filename['J_07'] = 'DSC_0701_'\n",
    "folder_to_filename['J_08'] = 'DSC_0734_'\n",
    "folder_to_filename['J_09'] = 'DSC_0810_'\n",
    "\n",
    "folder_to_filename['l'] = 'DSC_0809_'\n",
    "folder_to_filename['n'] = 'DSC_0806_'\n",
    "folder_to_filename['r'] = 'DSC_0807_'\n",
    "folder_to_filename['ry'] = 'DSC_0805_'\n",
    "folder_to_filename['t'] = 'DSC_0804_'\n",
    "\n",
    "folder_to_filename['S_01'] = 'DSC_0811_'\n",
    "folder_to_filename['S_02'] = 'DSC_0705_'\n",
    "folder_to_filename['S_03'] = 'DSC_0735_'\n",
    "\n",
    "folder_to_filename['W_01'] = 'DSC_0802_'\n",
    "folder_to_filename['W_02'] = 'DSC_0803_'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "1ac8817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./jk_data_only_22/video_details', './jk_data_only_22/openposedata']\n"
     ]
    }
   ],
   "source": [
    "print(subfolders)\n",
    "video_path = subfolders[0]\n",
    "data_path = subfolders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "f2197520",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = os.listdir(video_path)\n",
    "video_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "375acfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J_01.json', 'J_02.json', 'J_03.json', 'J_04.json', 'J_05.json', 'J_06.json', 'J_07.json', 'J_08.json', 'J_09.json', 'S_01.json', 'S_02.json', 'S_03.json', 'W_01.json', 'W_02.json', 'a.json', 'ax.json', 'l.json', 'n.json', 'r.json', 'ry.json', 't.json']\n"
     ]
    }
   ],
   "source": [
    "print(video_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed71a1",
   "metadata": {},
   "source": [
    "## Create the structure containing the JSONs(start frame, end frame, label for each pair) of each openpose folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "10861d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_end_frames=[]\n",
    "\n",
    "for i in range(0,len(video_files)):\n",
    "       with open(video_path+'/'+video_files[i], 'r') as j:\n",
    "            \n",
    "            contents = json.load(j)\n",
    "            start_end_frames.append(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c92d6",
   "metadata": {},
   "source": [
    "### Checking that each JSON contains an even number of values(since they are start-end frame pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "4a6a841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(video_files)):\n",
    "    print(len(start_end_frames[i]['squats'][0]['in_and_out']) % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "658ca6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_frame_no(frame):\n",
    "    \n",
    "    size = 1\n",
    "    tmp = frame\n",
    "    \n",
    "    while tmp >=10:\n",
    "        \n",
    "        tmp = tmp/10\n",
    "        size+=1\n",
    "        \n",
    "    leads=''\n",
    "    \n",
    "    for i in range(12-size):\n",
    "        \n",
    "        leads+='0'\n",
    "    \n",
    "    return leads + str(frame) + \"_keypoints.json\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7be7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940f6d45",
   "metadata": {},
   "source": [
    "## Trying to read from the openpose folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "97f3be51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'l',\n",
       " 'ry',\n",
       " 'a',\n",
       " 'J_07',\n",
       " 'J_05',\n",
       " 'W_02',\n",
       " 'J_06',\n",
       " 'S_01',\n",
       " 'J_08',\n",
       " 'S_03',\n",
       " 'W_01',\n",
       " 'J_09',\n",
       " 'ax',\n",
       " 'r',\n",
       " 'J_02',\n",
       " 'S_02',\n",
       " 'n',\n",
       " 'J_01',\n",
       " 'J_04',\n",
       " 'J_03']"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "01ab3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#But when two people are in frame,both have same number of (x,y) coordinates, but some end files have just\n",
    "#one person in frame, how to choose which one to use??(no depth information)\n",
    "def most_keypoints(data):\n",
    "    \n",
    "    l0 = data['people'][0]['pose_keypoints']\n",
    "    l1 = data['people'][1]['pose_keypoints']\n",
    "    \n",
    "    if len(l0) >= len(l1):\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "5bdfa3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "X=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "c2a490c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(video_files)):\n",
    "    #get the name of the folder in the openposedata(e.g. a, J_01 etc.)\n",
    "    folder = video_files[i].split('.')[0]\n",
    "    \n",
    "    labels = start_end_frames[i]['squats'][0]['class_label']\n",
    "    #In and out frames for the current folder\n",
    "    start_end = start_end_frames[i]['squats'][0]['in_and_out']\n",
    "    \n",
    "    converted_labels = [class_labels[label] for label in labels]\n",
    "    y = y+converted_labels\n",
    "    \n",
    "    file_name = folder_to_filename[folder]\n",
    "    path = data_path + '/' + folder + '/' + file_name\n",
    "    \n",
    "    for frame in range(0,len(start_end),2):\n",
    "        #get start and end frame for each squat\n",
    "        start_frame = start_end[frame]\n",
    "        end_frame = start_end[frame+1]\n",
    "        \n",
    "        frames_sequence=[]\n",
    "        #iterate through all the frames in between, open each json and add the list of (x,y) coordinates to the \n",
    "        #frames_sequence list\n",
    "        for sequence in range(start_frame,end_frame+1):\n",
    "            \n",
    "            frame_number_json = convert_to_frame_no(sequence)\n",
    "            \n",
    "            with open(path + frame_number_json, 'r') as j:\n",
    "        \n",
    "                json_data = json.load(j)\n",
    "                pos = 0\n",
    "                \n",
    "                if len(json_data['people']) > 1: \n",
    "                    \n",
    "                    pos = most_keypoints(json_data)\n",
    "                    \n",
    "                points_with_confidence = json_data['people'][pos]['pose_keypoints']\n",
    "                #remove the confidence values\n",
    "                keypoints = [(points_with_confidence[k],points_with_confidence[k+1]) for k in range(0,len(points_with_confidence)-2,3)]\n",
    "                \n",
    "                keypoints = list(itertools.chain(*keypoints))\n",
    "                \n",
    "                frames_sequence.append(keypoints)\n",
    "        \n",
    "        \n",
    "        X.append(frames_sequence)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "f12feccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-725-6c4156275ea8>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(X)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "8018c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  count is  70\n",
      "1  count is  57\n",
      "2  count is  55\n",
      "3  count is  55\n",
      "4  count is  54\n",
      "5  count is  5\n"
     ]
    }
   ],
   "source": [
    "#check the number of datapoints per class\n",
    "p = list(y)\n",
    "for i in range(0,6):\n",
    "    print(i,\" count is \", p.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b218ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb06319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b96db847",
   "metadata": {},
   "source": [
    "# Observations made so far:\n",
    "\n",
    "### Start and end frames each have 36 key_points total (which means 18 (x,y) pairs)\n",
    "### Some start frames have two people in them\n",
    "### Although some start frames have two people in them, some end frames end with just a person in frame\n",
    "### One of the files had a missing comma, which had to be added i.o.t. carry on reading the JSON\n",
    "### Incredibly few labelled points(only 296) --> SMOTE(Synthetic Minority Oversampling Technique), ADASYN(Adaptive Synthetic Sampling Approach )\n",
    "### Another reason for which the number of points is problematic --> the number of dimensions is 36 * number of frames per label, so curse of dimensionality(PCA is a must)\n",
    "### Over the 296 datapoints, the number of points belonging to class 5 (incorrect_out_knees) is incredibly small, will definitely lead to biases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923388c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947001af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb714603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
